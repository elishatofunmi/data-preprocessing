{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "state = tf.Variable(0, name= 'counter')\n",
    "constant = tf.constant(1)\n",
    "new_value = tf.add(state, constant)\n",
    "update = tf.assign(state, new_value)\n",
    "init = tf.global_variables_initializer() # must have all variables defined\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for _ in range(4):\n",
    "        sess.run(update)\n",
    "        print (sess.run(state))\n",
    "    sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24]]\n"
     ]
    }
   ],
   "source": [
    "matrix1 = tf.constant([[3,3,3]])\n",
    "matrix2 = tf.constant([[2],\n",
    "                       [2],\n",
    "                       [4]])\n",
    "product = tf.matmul(matrix1, matrix2) #np.dot(m1, m2)\n",
    "\n",
    "sess = tf.Session()\n",
    "result = sess.run(product)\n",
    "print (result)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[24]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    result2 = sess.run(product)\n",
    "    print (result2)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "housing_data_plus_bias = np.c_[np.ones((m,1)), housing.data]\n",
    "\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype = tf.float32, name = 'X')\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32, name = 'y')\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT,X)),XT),y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.67205572]\n",
      " [ 0.13052547]\n",
      " [ 0.37136889]\n",
      " [ 0.0418582 ]\n",
      " [ 0.54744363]\n",
      " [ 0.31627011]\n",
      " [ 0.18666577]]\n"
     ]
    }
   ],
   "source": [
    "value = tf.Variable(tf.random_uniform([6+1,1]), name = 'value')\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print (sess.run(value))\n",
    "    sess.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help (tf.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01033998]\n",
      " [ 0.08700991]\n",
      " [ 0.07862008]\n",
      " [ 0.34857392]\n",
      " [ 0.27331495]\n",
      " [ 0.34557152]\n",
      " [ 0.65058386]]\n"
     ]
    }
   ],
   "source": [
    "value_new = tf.Variable(tf.reshape(tf.random_uniform([6+1,1]), (-1,1)), name = 'value')\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print (sess.run(value_new))\n",
    "    sess.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually computing the gradients\n",
    "x = tf.constant(scaled_housing_data_plus_bias, dtype = tf.float32, name = \"X\")\n",
    "y = tf.constant(housing.target.reshape(-1,1), dtype = tf.float32,  name = 'y')\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1,0,1.0), name = 'theta')\n",
    "y_pred = tf.matmul(X, theta, name = 'predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name = 'mse')\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print (\"Epoch\", epoch, \"MSE = \", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function convert_to_tensor in module tensorflow.python.framework.ops:\n",
      "\n",
      "convert_to_tensor(value, dtype=None, name=None, preferred_dtype=None)\n",
      "    Converts the given `value` to a `Tensor`.\n",
      "    \n",
      "    This function converts Python objects of various types to `Tensor`\n",
      "    objects. It accepts `Tensor` objects, numpy arrays, Python lists,\n",
      "    and Python scalars. For example:\n",
      "    \n",
      "    ```python\n",
      "    import numpy as np\n",
      "    \n",
      "    def my_func(arg):\n",
      "      arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n",
      "      return tf.matmul(arg, arg) + arg\n",
      "    \n",
      "    # The following calls are equivalent.\n",
      "    value_1 = my_func(tf.constant([[1.0, 2.0], [3.0, 4.0]]))\n",
      "    value_2 = my_func([[1.0, 2.0], [3.0, 4.0]])\n",
      "    value_3 = my_func(np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32))\n",
      "    ```\n",
      "    \n",
      "    This function can be useful when composing a new operation in Python\n",
      "    (such as `my_func` in the example above). All standard Python op\n",
      "    constructors apply this function to each of their Tensor-valued\n",
      "    inputs, which allows those ops to accept numpy arrays, Python lists,\n",
      "    and scalars in addition to `Tensor` objects.\n",
      "    \n",
      "    Args:\n",
      "      value: An object whose type has a registered `Tensor` conversion function.\n",
      "      dtype: Optional element type for the returned tensor. If missing, the\n",
      "        type is inferred from the type of `value`.\n",
      "      name: Optional name to use if a new `Tensor` is created.\n",
      "      preferred_dtype: Optional element type for the returned tensor,\n",
      "        used when dtype is None. In some cases, a caller may not have a\n",
      "        dtype in mind when converting to a tensor, so preferred_dtype\n",
      "        can be used as a soft preference.  If the conversion to\n",
      "        `preferred_dtype` is not possible, this argument has no effect.\n",
      "    \n",
      "    Returns:\n",
      "      An `Output` based on `value`.\n",
      "    \n",
      "    Raises:\n",
      "      TypeError: If no conversion function is registered for `value`.\n",
      "      RuntimeError: If a registered conversion function returns an invalid value.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help (tf.convert_to_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19208399]\n",
      " [-0.10974146]\n",
      " [-0.04424045]\n",
      " [ 0.22700138]\n",
      " [ 0.60989412]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "target = iris.target\n",
    "m, n = data.shape\n",
    "data_bias = np.c_[np.ones((m, 1)), data]\n",
    "\n",
    "x = tf.constant(data_bias, dtype = tf.float64, name = 'data_bias')\n",
    "X = tf.convert_to_tensor(x,dtype = tf.float64, name = 'convert_x')\n",
    "\n",
    "y = tf.constant(target.reshape(-1,1), dtype = tf.float64, name = 'target')\n",
    "Y = tf.convert_to_tensor(y, dtype = tf.float64, name = 'convert_y')\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), Y)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    theta_value = theta.eval()\n",
    "    tensor = tf.constant(theta_value)\n",
    "    value = tensor.eval()\n",
    "    print (value)\n",
    "    sess.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.79612517]\n",
      " [ 0.95541716]\n",
      " [-0.79291511]\n",
      " [-0.77911663]\n",
      " [ 0.48663473]\n",
      " [ 0.1560421 ]\n",
      " [-0.77413726]\n",
      " [ 0.88263321]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn as sk\n",
    "theta = tf.Variable(tf.random_uniform([8, 1], -1.0,1.0), name = 'theta')\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print (sess.run(theta))\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 80.0112\n",
      "Epoch 100 MSE = 0.0689921\n",
      "Epoch 200 MSE = 0.0648672\n",
      "Epoch 300 MSE = 0.0620683\n",
      "Epoch 400 MSE = 0.0598761\n",
      "Epoch 500 MSE = 0.0581372\n",
      "Epoch 600 MSE = 0.056739\n",
      "Epoch 700 MSE = 0.0555991\n",
      "Epoch 800 MSE = 0.0546565\n",
      "Epoch 900 MSE = 0.0538664\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "m, n = data.shape\n",
    "\n",
    "x = tf.constant(data_bias, dtype = tf.float32, name = 'data_bias')\n",
    "X = tf.convert_to_tensor(x,dtype = tf.float32, name = 'convert_x')\n",
    "\n",
    "y = tf.constant(target.reshape(-1,1), dtype = tf.float32, name = 'target')\n",
    "Y = tf.convert_to_tensor(y, dtype = tf.float32, name = 'convert_y')\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0,1.0), name = 'theta')\n",
    "y_pred = tf.matmul(X, theta, name = 'predictions')\n",
    "error = y_pred - Y\n",
    "mse = tf.reduce_mean(tf.square(error), name = 'mse')\n",
    "gradients = 2/m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print (\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 29.0399\n",
      "Epoch 100 MSE = 0.139374\n",
      "Epoch 200 MSE = 0.114833\n",
      "Epoch 300 MSE = 0.0974138\n",
      "Epoch 400 MSE = 0.0847403\n",
      "Epoch 500 MSE = 0.0755087\n",
      "Epoch 600 MSE = 0.0687736\n",
      "Epoch 700 MSE = 0.0638497\n",
      "Epoch 800 MSE = 0.0602404\n",
      "Epoch 900 MSE = 0.0575853\n"
     ]
    }
   ],
   "source": [
    "# using tensorflow autodiff feature\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "m, n = data.shape\n",
    "\n",
    "x = tf.constant(data_bias, dtype = tf.float32, name = 'data_bias')\n",
    "X = tf.convert_to_tensor(x,dtype = tf.float32, name = 'convert_x')\n",
    "\n",
    "y = tf.constant(target.reshape(-1,1), dtype = tf.float32, name = 'target')\n",
    "Y = tf.convert_to_tensor(y, dtype = tf.float32, name = 'convert_y')\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0,1.0), name = 'theta')\n",
    "y_pred = tf.matmul(X, theta, name = 'predictions')\n",
    "error = y_pred - Y\n",
    "mse = tf.reduce_mean(tf.square(error), name = 'mse')\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print (\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 MSE = 18.9902\n",
      "Epoch 100 MSE = 0.0809686\n",
      "Epoch 200 MSE = 0.0736481\n",
      "Epoch 300 MSE = 0.0683972\n",
      "Epoch 400 MSE = 0.0644816\n",
      "Epoch 500 MSE = 0.0615409\n",
      "Epoch 600 MSE = 0.0593133\n",
      "Epoch 700 MSE = 0.0576088\n",
      "Epoch 800 MSE = 0.0562891\n",
      "Epoch 900 MSE = 0.0552533\n"
     ]
    }
   ],
   "source": [
    "# using an optimizer\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "m, n = data.shape\n",
    "\n",
    "x = tf.constant(data_bias, dtype = tf.float32, name = 'data_bias')\n",
    "X = tf.convert_to_tensor(x,dtype = tf.float32, name = 'convert_x')\n",
    "\n",
    "y = tf.constant(target.reshape(-1,1), dtype = tf.float32, name = 'target')\n",
    "Y = tf.convert_to_tensor(y, dtype = tf.float32, name = 'convert_y')\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n+1, 1], -1.0,1.0), name = 'theta')\n",
    "y_pred = tf.matmul(X, theta, name = 'predictions')\n",
    "error = y_pred - Y\n",
    "mse = tf.reduce_mean(tf.square(error), name = 'mse')\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate)\n",
    "\n",
    "training_op = optimizer.minimize(mse)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100 == 0:\n",
    "            print (\"Epoch\", epoch, \"MSE =\", mse.eval())\n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  7.  8.]]\n",
      "[[  9.  10.  11.]\n",
      " [ 12.  13.  14.]]\n"
     ]
    }
   ],
   "source": [
    "# implementing Mini-batch gradient Descent.\n",
    "# for this we will need to replace X and Y at every iteration with the next mini-batch.\n",
    "# the simplest way to do this is to use placeholder nodes.\n",
    "\n",
    "# placeholders are typically used to pass the training data to tensorflow during training.\n",
    "A = tf.placeholder(tf.float32, shape = (None, 3))\n",
    "B = A + 5\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    B_val_1 = B.eval(feed_dict = {A:[[1,2,3]]})\n",
    "    B_val_2 = B.eval(feed_dict = {A:[[4,5,6],[7,8,9]]})\n",
    "    sess.close()\n",
    "    \n",
    "print (B_val_1)\n",
    "print (B_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 5),\n",
       " TensorShape([Dimension(150), Dimension(4)]),\n",
       " TensorShape([Dimension(150), Dimension(1)]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bias.shape, x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(150), Dimension(4)]), TensorShape([Dimension(150)]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_place.shape, y_place.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(iris.data, dtype = tf.float32, name = 'data_bias')\n",
    "X = tf.convert_to_tensor(x,dtype = tf.float32, name = 'convert_x')\n",
    "\n",
    "y = tf.constant(target.reshape(-1,1), dtype = tf.float32, name = 'target')\n",
    "Y = tf.convert_to_tensor(y, dtype = tf.float32, name = 'convert_y')\n",
    "\n",
    "x_place = tf.placeholder(tf.float32, shape = (m, n), name = 'place_x')\n",
    "y_place = tf.placeholder(tf.float32, shape = (m,), name = 'place_y')\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m/batch_size))\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    x = iris.data\n",
    "    y = iris.target\n",
    "    return x, y\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            x_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            sess.run(training_op, feed_dict = {x_place: x_batch, y_place: y_batch})\n",
    "            best_theta = theta.eval()\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\SPB_Data\\\\churn prediction DSN kaggle competition 1 2018\\\\BestGitWork'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\SPB_Data\\churn prediction DSN kaggle competition 1 2018\\BestGitWork\\my_final_model.ckpt\n",
      "INFO:tensorflow:Restoring parameters from C:\\SPB_Data\\churn prediction DSN kaggle competition 1 2018\\BestGitWork\\my_final_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "theta = tf.Variable(tf.random_uniform([n+1,1], -1.0,1.0), name = 'theta')\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        if epoch % 100  == 0: # checkpoint every 100 epochs\n",
    "            save_path = saver.save(sess, \"C:\\\\SPB_Data\\\\churn prediction DSN kaggle competition 1 2018\\\\BestGitWork\\my_model.ckpt\")\n",
    "            \n",
    "        sess.run(training_op)\n",
    "    best_theta = theta.eval()\n",
    "    save_path = saver.save(sess, \"C:\\\\SPB_Data\\\\churn prediction DSN kaggle competition 1 2018\\\\BestGitWork\\my_final_model.ckpt\")\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"C:\\\\SPB_Data\\\\churn prediction DSN kaggle competition 1 2018\\\\BestGitWork\\my_final_model.ckpt\")\n",
    "    \n",
    "    # the following saver only saves or restore only the theta variable under the name weights\n",
    "    saver = tf.train.Saver({\"weights\": theta})\n",
    "    \n",
    "    # By default the save() method also saves the structure of the graph in the second file with the\n",
    "    # same name plus a .meta extension. \n",
    "    # we can load the graph structure with the following\n",
    "    saver = tf.train.import_meta_graph(\"C:\\\\SPB_Data\\\\churn prediction DSN kaggle competition 1 2018\\\\BestGitWork\\my_final_model.ckpt.meta\")\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"C:\\\\SPB_Data\\\\churn prediction DSN kaggle competition 1 2018\\\\BestGitWork\\my_final_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the graph and training curves using TensorBoard\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = 'tf_logs'\n",
    "logdir = \"{}/run-{}\".format(root_logdir, now)\n",
    "\n",
    "x = tf.constant(iris.data, dtype = tf.float32, name = 'data_bias')\n",
    "X = tf.convert_to_tensor(x,dtype = tf.float32, name = 'convert_x')\n",
    "\n",
    "y = tf.constant(target.reshape(-1,1), dtype = tf.float32, name = 'target')\n",
    "Y = tf.convert_to_tensor(y, dtype = tf.float32, name = 'convert_y')\n",
    "\n",
    "x_place = tf.placeholder(tf.float32, shape = (m, n), name = 'place_x')\n",
    "y_place = tf.placeholder(tf.float32, shape = (m,), name = 'place_y')\n",
    "\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m/batch_size))\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    x = iris.data\n",
    "    y = iris.target\n",
    "    return x, y\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    mse_summary = tf.summary.scalar(\"MSE\", mse)\n",
    "    file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "    for batch_index in range(n_batches):\n",
    "        x_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "        if batch_index % 10 == 0:\n",
    "            summary_str = mse_summary.eval(feed_dict = {x_place: x_batch, y_place: y_batch})\n",
    "            step = epoch * n_batches + batch_index\n",
    "            file_writer.add_summary(summary_str, step)\n",
    "        sess.run(training_op, feed_dict = {x_place: x_batch, y_place: y_batch})\n",
    "\n",
    "\n",
    "    file_writer.close()\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\SPB_Data\\\\churn prediction DSN kaggle competition 1 2018\\\\BestGitWork'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " '.ipynb_checkpoints',\n",
       " 'checkpoint',\n",
       " 'my_final_model.ckpt.data-00000-of-00001',\n",
       " 'my_final_model.ckpt.index',\n",
       " 'my_final_model.ckpt.meta',\n",
       " 'my_model.ckpt.data-00000-of-00001',\n",
       " 'my_model.ckpt.index',\n",
       " 'my_model.ckpt.meta',\n",
       " 'path_files.ipynb',\n",
       " 'Tensorflow.ipynb',\n",
       " 'tf_logs']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('C:\\\\SPB_Data\\\\churn prediction DSN kaggle competition 1 2018\\\\BestGitWork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isdir('C:\\\\SPB_Data\\\\churn prediction DSN kaggle competition 1 2018\\\\BestGitWork\\tf_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
