{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "x = iris.data[:, [2,3]] # petal length, petal width\n",
    "y = (iris.target == 0).astype(np.int) # iris setosa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_clf = Perceptron(random_state = 42)\n",
    "per_clf.fit(x, y)\n",
    "y_pred = per_clf.predict([[2,0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perceptron learning algorithm strongly resembles Stochastic Gradient\n",
    "# Descent. scikit_learn perceptron class is equivalent to using an \n",
    "# SGDClassifier with the following hyperparameters: loss = 'perceptron',\n",
    "# learning_rate = 'constant', eta0 = 1(the learning rate) and penalty = None\n",
    "# (no regularization).\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANIING AN MLP WITH TENSORFLOW'S HIGH-LEVEL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\ACER\\AppData\\Local\\Temp\\tmpc03kpxuk\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000000009222400>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\ACER\\\\AppData\\\\Local\\\\Temp\\\\tmpc03kpxuk'}\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\dnn.py:192: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\ACER\\AppData\\Local\\Temp\\tmpc03kpxuk\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.90583, step = 1\n",
      "INFO:tensorflow:global_step/sec: 276.237\n",
      "INFO:tensorflow:loss = 0.0209601, step = 101 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.105\n",
      "INFO:tensorflow:loss = 0.00553809, step = 201 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.068\n",
      "INFO:tensorflow:loss = 0.00288496, step = 301 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.541\n",
      "INFO:tensorflow:loss = 0.0018754, step = 401 (0.338 sec)\n",
      "INFO:tensorflow:global_step/sec: 190.105\n",
      "INFO:tensorflow:loss = 0.00136052, step = 501 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.295\n",
      "INFO:tensorflow:loss = 0.00105379, step = 601 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.082\n",
      "INFO:tensorflow:loss = 0.000852456, step = 701 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.535\n",
      "INFO:tensorflow:loss = 0.000711213, step = 801 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.728\n",
      "INFO:tensorflow:loss = 0.000607308, step = 901 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.723\n",
      "INFO:tensorflow:loss = 0.000528239, step = 1001 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.055\n",
      "INFO:tensorflow:loss = 0.000466042, step = 1101 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.612\n",
      "INFO:tensorflow:loss = 0.000415959, step = 1201 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.464\n",
      "INFO:tensorflow:loss = 0.000374893, step = 1301 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.526\n",
      "INFO:tensorflow:loss = 0.000340664, step = 1401 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.054\n",
      "INFO:tensorflow:loss = 0.000311662, step = 1501 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.884\n",
      "INFO:tensorflow:loss = 0.000286916, step = 1601 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.765\n",
      "INFO:tensorflow:loss = 0.0002655, step = 1701 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.792\n",
      "INFO:tensorflow:loss = 0.000246867, step = 1801 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.208\n",
      "INFO:tensorflow:loss = 0.000230486, step = 1901 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.74\n",
      "INFO:tensorflow:loss = 0.000215973, step = 2001 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.717\n",
      "INFO:tensorflow:loss = 0.000203047, step = 2101 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.516\n",
      "INFO:tensorflow:loss = 0.000191473, step = 2201 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.143\n",
      "INFO:tensorflow:loss = 0.000181066, step = 2301 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.511\n",
      "INFO:tensorflow:loss = 0.00017165, step = 2401 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.65\n",
      "INFO:tensorflow:loss = 0.000163079, step = 2501 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.742\n",
      "INFO:tensorflow:loss = 0.000155247, step = 2601 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.742\n",
      "INFO:tensorflow:loss = 0.000148093, step = 2701 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.242\n",
      "INFO:tensorflow:loss = 0.000141538, step = 2801 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.402\n",
      "INFO:tensorflow:loss = 0.000135507, step = 2901 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.081\n",
      "INFO:tensorflow:loss = 0.000129901, step = 3001 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.485\n",
      "INFO:tensorflow:loss = 0.000124767, step = 3101 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.717\n",
      "INFO:tensorflow:loss = 0.000119939, step = 3201 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.511\n",
      "INFO:tensorflow:loss = 0.000115467, step = 3301 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.793\n",
      "INFO:tensorflow:loss = 0.000111302, step = 3401 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.07\n",
      "INFO:tensorflow:loss = 0.000107387, step = 3501 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.231\n",
      "INFO:tensorflow:loss = 0.000103725, step = 3601 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.297\n",
      "INFO:tensorflow:loss = 0.000100294, step = 3701 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.842\n",
      "INFO:tensorflow:loss = 9.70458e-05, step = 3801 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.083\n",
      "INFO:tensorflow:loss = 9.39998e-05, step = 3901 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 294.541\n",
      "INFO:tensorflow:loss = 9.10928e-05, step = 4001 (0.340 sec)\n",
      "INFO:tensorflow:global_step/sec: 290.268\n",
      "INFO:tensorflow:loss = 8.83922e-05, step = 4101 (0.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.235\n",
      "INFO:tensorflow:loss = 8.58266e-05, step = 4201 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.102\n",
      "INFO:tensorflow:loss = 8.33881e-05, step = 4301 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.078\n",
      "INFO:tensorflow:loss = 8.10687e-05, step = 4401 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.495\n",
      "INFO:tensorflow:loss = 7.88843e-05, step = 4501 (0.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.083\n",
      "INFO:tensorflow:loss = 7.67833e-05, step = 4601 (0.355 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.722\n",
      "INFO:tensorflow:loss = 7.48014e-05, step = 4701 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.125\n",
      "INFO:tensorflow:loss = 7.29029e-05, step = 4801 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.404\n",
      "INFO:tensorflow:loss = 7.10996e-05, step = 4901 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.281\n",
      "INFO:tensorflow:loss = 6.93639e-05, step = 5001 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.084\n",
      "INFO:tensorflow:loss = 6.77156e-05, step = 5101 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.231\n",
      "INFO:tensorflow:loss = 6.61268e-05, step = 5201 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.701\n",
      "INFO:tensorflow:loss = 6.46373e-05, step = 5301 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.402\n",
      "INFO:tensorflow:loss = 6.31438e-05, step = 5401 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.202\n",
      "INFO:tensorflow:loss = 6.17735e-05, step = 5501 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.852\n",
      "INFO:tensorflow:loss = 6.04587e-05, step = 5601 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.953\n",
      "INFO:tensorflow:loss = 5.91638e-05, step = 5701 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.652\n",
      "INFO:tensorflow:loss = 5.79126e-05, step = 5801 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.192\n",
      "INFO:tensorflow:loss = 5.67249e-05, step = 5901 (0.574 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.82\n",
      "INFO:tensorflow:loss = 5.55809e-05, step = 6001 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.95\n",
      "INFO:tensorflow:loss = 5.44925e-05, step = 6101 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.742\n",
      "INFO:tensorflow:loss = 5.3428e-05, step = 6201 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.212\n",
      "INFO:tensorflow:loss = 5.23991e-05, step = 6301 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.957\n",
      "INFO:tensorflow:loss = 5.141e-05, step = 6401 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.795\n",
      "INFO:tensorflow:loss = 5.04885e-05, step = 6501 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.237\n",
      "INFO:tensorflow:loss = 4.95232e-05, step = 6601 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.9\n",
      "INFO:tensorflow:loss = 4.86373e-05, step = 6701 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.221\n",
      "INFO:tensorflow:loss = 4.77793e-05, step = 6801 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.705\n",
      "INFO:tensorflow:loss = 4.69292e-05, step = 6901 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.721\n",
      "INFO:tensorflow:loss = 4.61586e-05, step = 7001 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.237\n",
      "INFO:tensorflow:loss = 4.53601e-05, step = 7101 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.686\n",
      "INFO:tensorflow:loss = 4.46093e-05, step = 7201 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.371\n",
      "INFO:tensorflow:loss = 4.38784e-05, step = 7301 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.396\n",
      "INFO:tensorflow:loss = 4.31593e-05, step = 7401 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.95\n",
      "INFO:tensorflow:loss = 4.24721e-05, step = 7501 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.934\n",
      "INFO:tensorflow:loss = 4.17769e-05, step = 7601 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.906\n",
      "INFO:tensorflow:loss = 4.11413e-05, step = 7701 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.117\n",
      "INFO:tensorflow:loss = 4.05057e-05, step = 7801 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.738\n",
      "INFO:tensorflow:loss = 3.99058e-05, step = 7901 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.632\n",
      "INFO:tensorflow:loss = 3.92901e-05, step = 8001 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.741\n",
      "INFO:tensorflow:loss = 3.86942e-05, step = 8101 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.242\n",
      "INFO:tensorflow:loss = 3.8142e-05, step = 8201 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.593\n",
      "INFO:tensorflow:loss = 3.76096e-05, step = 8301 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.468\n",
      "INFO:tensorflow:loss = 3.70376e-05, step = 8401 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.873\n",
      "INFO:tensorflow:loss = 3.65172e-05, step = 8501 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.654\n",
      "INFO:tensorflow:loss = 3.60325e-05, step = 8601 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.438\n",
      "INFO:tensorflow:loss = 3.55399e-05, step = 8701 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.389\n",
      "INFO:tensorflow:loss = 3.50353e-05, step = 8801 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.221\n",
      "INFO:tensorflow:loss = 3.45825e-05, step = 8901 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.485\n",
      "INFO:tensorflow:loss = 3.41216e-05, step = 9001 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.297\n",
      "INFO:tensorflow:loss = 3.36767e-05, step = 9101 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.58\n",
      "INFO:tensorflow:loss = 3.32476e-05, step = 9201 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.728\n",
      "INFO:tensorflow:loss = 3.28066e-05, step = 9301 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.393\n",
      "INFO:tensorflow:loss = 3.24014e-05, step = 9401 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.728\n",
      "INFO:tensorflow:loss = 3.19803e-05, step = 9501 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.532\n",
      "INFO:tensorflow:loss = 3.15949e-05, step = 9601 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.209\n",
      "INFO:tensorflow:loss = 3.11818e-05, step = 9701 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.958\n",
      "INFO:tensorflow:loss = 3.08043e-05, step = 9801 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.953\n",
      "INFO:tensorflow:loss = 3.04428e-05, step = 9901 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.202\n",
      "INFO:tensorflow:loss = 3.00694e-05, step = 10001 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.438\n",
      "INFO:tensorflow:loss = 2.97237e-05, step = 10101 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.452\n",
      "INFO:tensorflow:loss = 2.93821e-05, step = 10201 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.836\n",
      "INFO:tensorflow:loss = 2.90404e-05, step = 10301 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.179\n",
      "INFO:tensorflow:loss = 2.86948e-05, step = 10401 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.297\n",
      "INFO:tensorflow:loss = 2.83769e-05, step = 10501 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.97\n",
      "INFO:tensorflow:loss = 2.80631e-05, step = 10601 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.744\n",
      "INFO:tensorflow:loss = 2.77532e-05, step = 10701 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.179\n",
      "INFO:tensorflow:loss = 2.74274e-05, step = 10801 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.942\n",
      "INFO:tensorflow:loss = 2.71414e-05, step = 10901 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.221\n",
      "INFO:tensorflow:loss = 2.68593e-05, step = 11001 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.651\n",
      "INFO:tensorflow:loss = 2.65494e-05, step = 11101 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.24\n",
      "INFO:tensorflow:loss = 2.62872e-05, step = 11201 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.82\n",
      "INFO:tensorflow:loss = 2.60091e-05, step = 11301 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.452\n",
      "INFO:tensorflow:loss = 2.5731e-05, step = 11401 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.221\n",
      "INFO:tensorflow:loss = 2.54727e-05, step = 11501 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.514\n",
      "INFO:tensorflow:loss = 2.52065e-05, step = 11601 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.508\n",
      "INFO:tensorflow:loss = 2.49682e-05, step = 11701 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.169\n",
      "INFO:tensorflow:loss = 2.47099e-05, step = 11801 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.098\n",
      "INFO:tensorflow:loss = 2.44477e-05, step = 11901 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.808\n",
      "INFO:tensorflow:loss = 2.42014e-05, step = 12001 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.099\n",
      "INFO:tensorflow:loss = 2.39749e-05, step = 12101 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.44\n",
      "INFO:tensorflow:loss = 2.37405e-05, step = 12201 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.485\n",
      "INFO:tensorflow:loss = 2.34982e-05, step = 12301 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.295\n",
      "INFO:tensorflow:loss = 2.32836e-05, step = 12401 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.651\n",
      "INFO:tensorflow:loss = 2.30611e-05, step = 12501 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.545\n",
      "INFO:tensorflow:loss = 2.28545e-05, step = 12601 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.511\n",
      "INFO:tensorflow:loss = 2.264e-05, step = 12701 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.401\n",
      "INFO:tensorflow:loss = 2.24255e-05, step = 12801 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.457\n",
      "INFO:tensorflow:loss = 2.22109e-05, step = 12901 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.853\n",
      "INFO:tensorflow:loss = 2.20123e-05, step = 13001 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.632\n",
      "INFO:tensorflow:loss = 2.18216e-05, step = 13101 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.345\n",
      "INFO:tensorflow:loss = 2.16269e-05, step = 13201 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.327\n",
      "INFO:tensorflow:loss = 2.14322e-05, step = 13301 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.202\n",
      "INFO:tensorflow:loss = 2.12455e-05, step = 13401 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.226\n",
      "INFO:tensorflow:loss = 2.10706e-05, step = 13501 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.395\n",
      "INFO:tensorflow:loss = 2.0868e-05, step = 13601 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.457\n",
      "INFO:tensorflow:loss = 2.06972e-05, step = 13701 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.26\n",
      "INFO:tensorflow:loss = 2.05184e-05, step = 13801 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.728\n",
      "INFO:tensorflow:loss = 2.03436e-05, step = 13901 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.899\n",
      "INFO:tensorflow:loss = 2.01688e-05, step = 14001 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.371\n",
      "INFO:tensorflow:loss = 2.00138e-05, step = 14101 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.005\n",
      "INFO:tensorflow:loss = 1.98589e-05, step = 14201 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.836\n",
      "INFO:tensorflow:loss = 1.96801e-05, step = 14301 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.725\n",
      "INFO:tensorflow:loss = 1.95172e-05, step = 14401 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.26\n",
      "INFO:tensorflow:loss = 1.93503e-05, step = 14501 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.121\n",
      "INFO:tensorflow:loss = 1.91914e-05, step = 14601 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.899\n",
      "INFO:tensorflow:loss = 1.90563e-05, step = 14701 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.765\n",
      "INFO:tensorflow:loss = 1.88894e-05, step = 14801 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.072\n",
      "INFO:tensorflow:loss = 1.87225e-05, step = 14901 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.227\n",
      "INFO:tensorflow:loss = 1.85795e-05, step = 15001 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.067\n",
      "INFO:tensorflow:loss = 1.84405e-05, step = 15101 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.202\n",
      "INFO:tensorflow:loss = 1.82776e-05, step = 15201 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.083\n",
      "INFO:tensorflow:loss = 1.81544e-05, step = 15301 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.471\n",
      "INFO:tensorflow:loss = 1.80193e-05, step = 15401 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.237\n",
      "INFO:tensorflow:loss = 1.78882e-05, step = 15501 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.491\n",
      "INFO:tensorflow:loss = 1.7761e-05, step = 15601 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.583\n",
      "INFO:tensorflow:loss = 1.7626e-05, step = 15701 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.652\n",
      "INFO:tensorflow:loss = 1.75028e-05, step = 15801 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.988\n",
      "INFO:tensorflow:loss = 1.73598e-05, step = 15901 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.705\n",
      "INFO:tensorflow:loss = 1.72366e-05, step = 16001 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.404\n",
      "INFO:tensorflow:loss = 1.71015e-05, step = 16101 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.196\n",
      "INFO:tensorflow:loss = 1.69823e-05, step = 16201 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.457\n",
      "INFO:tensorflow:loss = 1.68552e-05, step = 16301 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.787\n",
      "INFO:tensorflow:loss = 1.6736e-05, step = 16401 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.721\n",
      "INFO:tensorflow:loss = 1.66208e-05, step = 16501 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.738\n",
      "INFO:tensorflow:loss = 1.65055e-05, step = 16601 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.888\n",
      "INFO:tensorflow:loss = 1.63744e-05, step = 16701 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.401\n",
      "INFO:tensorflow:loss = 1.62671e-05, step = 16801 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.009\n",
      "INFO:tensorflow:loss = 1.61479e-05, step = 16901 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.51\n",
      "INFO:tensorflow:loss = 1.60486e-05, step = 17001 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.729\n",
      "INFO:tensorflow:loss = 1.59294e-05, step = 17101 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.404\n",
      "INFO:tensorflow:loss = 1.58023e-05, step = 17201 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.125\n",
      "INFO:tensorflow:loss = 1.5699e-05, step = 17301 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.174\n",
      "INFO:tensorflow:loss = 1.55957e-05, step = 17401 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.072\n",
      "INFO:tensorflow:loss = 1.55083e-05, step = 17501 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.906\n",
      "INFO:tensorflow:loss = 1.5401e-05, step = 17601 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.302\n",
      "INFO:tensorflow:loss = 1.52858e-05, step = 17701 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.75\n",
      "INFO:tensorflow:loss = 1.51904e-05, step = 17801 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.541\n",
      "INFO:tensorflow:loss = 1.50871e-05, step = 17901 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.907\n",
      "INFO:tensorflow:loss = 1.49957e-05, step = 18001 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.75\n",
      "INFO:tensorflow:loss = 1.48845e-05, step = 18101 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.65\n",
      "INFO:tensorflow:loss = 1.4801e-05, step = 18201 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.404\n",
      "INFO:tensorflow:loss = 1.47096e-05, step = 18301 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.302\n",
      "INFO:tensorflow:loss = 1.45944e-05, step = 18401 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.174\n",
      "INFO:tensorflow:loss = 1.45189e-05, step = 18501 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.756\n",
      "INFO:tensorflow:loss = 1.44236e-05, step = 18601 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.813\n",
      "INFO:tensorflow:loss = 1.43401e-05, step = 18701 (0.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.226\n",
      "INFO:tensorflow:loss = 1.42607e-05, step = 18801 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.465\n",
      "INFO:tensorflow:loss = 1.41653e-05, step = 18901 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.076\n",
      "INFO:tensorflow:loss = 1.40858e-05, step = 19001 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.994\n",
      "INFO:tensorflow:loss = 1.39746e-05, step = 19101 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.804\n",
      "INFO:tensorflow:loss = 1.39031e-05, step = 19201 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.229\n",
      "INFO:tensorflow:loss = 1.38236e-05, step = 19301 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.96\n",
      "INFO:tensorflow:loss = 1.37441e-05, step = 19401 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.722\n",
      "INFO:tensorflow:loss = 1.36647e-05, step = 19501 (0.449 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.226\n",
      "INFO:tensorflow:loss = 1.35773e-05, step = 19601 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.989\n",
      "INFO:tensorflow:loss = 1.34779e-05, step = 19701 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.38\n",
      "INFO:tensorflow:loss = 1.34104e-05, step = 19801 (0.586 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.227\n",
      "INFO:tensorflow:loss = 1.33389e-05, step = 19901 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.511\n",
      "INFO:tensorflow:loss = 1.32554e-05, step = 20001 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.201\n",
      "INFO:tensorflow:loss = 1.3172e-05, step = 20101 (0.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.738\n",
      "INFO:tensorflow:loss = 1.31084e-05, step = 20201 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.227\n",
      "INFO:tensorflow:loss = 1.3021e-05, step = 20301 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.872\n",
      "INFO:tensorflow:loss = 1.29336e-05, step = 20401 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.255\n",
      "INFO:tensorflow:loss = 1.28581e-05, step = 20501 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.852\n",
      "INFO:tensorflow:loss = 1.27945e-05, step = 20601 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.404\n",
      "INFO:tensorflow:loss = 1.2723e-05, step = 20701 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.852\n",
      "INFO:tensorflow:loss = 1.26594e-05, step = 20801 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.07\n",
      "INFO:tensorflow:loss = 1.258e-05, step = 20901 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.756\n",
      "INFO:tensorflow:loss = 1.25164e-05, step = 21001 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.07\n",
      "INFO:tensorflow:loss = 1.24528e-05, step = 21101 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.227\n",
      "INFO:tensorflow:loss = 1.23734e-05, step = 21201 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.97\n",
      "INFO:tensorflow:loss = 1.23098e-05, step = 21301 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.345\n",
      "INFO:tensorflow:loss = 1.22383e-05, step = 21401 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.787\n",
      "INFO:tensorflow:loss = 1.21628e-05, step = 21501 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.75\n",
      "INFO:tensorflow:loss = 1.20873e-05, step = 21601 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.041\n",
      "INFO:tensorflow:loss = 1.20277e-05, step = 21701 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.201\n",
      "INFO:tensorflow:loss = 1.19721e-05, step = 21801 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.668\n",
      "INFO:tensorflow:loss = 1.19125e-05, step = 21901 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.295\n",
      "INFO:tensorflow:loss = 1.18489e-05, step = 22001 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.082\n",
      "INFO:tensorflow:loss = 1.17813e-05, step = 22101 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.839\n",
      "INFO:tensorflow:loss = 1.17217e-05, step = 22201 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.418\n",
      "INFO:tensorflow:loss = 1.16741e-05, step = 22301 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.934\n",
      "INFO:tensorflow:loss = 1.16184e-05, step = 22401 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.987\n",
      "INFO:tensorflow:loss = 1.15549e-05, step = 22501 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.987\n",
      "INFO:tensorflow:loss = 1.14992e-05, step = 22601 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.237\n",
      "INFO:tensorflow:loss = 1.14396e-05, step = 22701 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.988\n",
      "INFO:tensorflow:loss = 1.13721e-05, step = 22801 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.212\n",
      "INFO:tensorflow:loss = 1.13125e-05, step = 22901 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.327\n",
      "INFO:tensorflow:loss = 1.12449e-05, step = 23001 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.832\n",
      "INFO:tensorflow:loss = 1.11893e-05, step = 23101 (0.540 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.039\n",
      "INFO:tensorflow:loss = 1.11337e-05, step = 23201 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.6\n",
      "INFO:tensorflow:loss = 1.1086e-05, step = 23301 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.26\n",
      "INFO:tensorflow:loss = 1.10224e-05, step = 23401 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.58\n",
      "INFO:tensorflow:loss = 1.09589e-05, step = 23501 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.082\n",
      "INFO:tensorflow:loss = 1.09191e-05, step = 23601 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.297\n",
      "INFO:tensorflow:loss = 1.08595e-05, step = 23701 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.452\n",
      "INFO:tensorflow:loss = 1.08118e-05, step = 23801 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.227\n",
      "INFO:tensorflow:loss = 1.07483e-05, step = 23901 (0.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.041\n",
      "INFO:tensorflow:loss = 1.06926e-05, step = 24001 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.039\n",
      "INFO:tensorflow:loss = 1.0641e-05, step = 24101 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.684\n",
      "INFO:tensorflow:loss = 1.05854e-05, step = 24201 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.402\n",
      "INFO:tensorflow:loss = 1.05456e-05, step = 24301 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.252\n",
      "INFO:tensorflow:loss = 1.049e-05, step = 24401 (0.455 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.209\n",
      "INFO:tensorflow:loss = 1.04463e-05, step = 24501 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.327\n",
      "INFO:tensorflow:loss = 1.04105e-05, step = 24601 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.777\n",
      "INFO:tensorflow:loss = 1.03629e-05, step = 24701 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.418\n",
      "INFO:tensorflow:loss = 1.03033e-05, step = 24801 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.828\n",
      "INFO:tensorflow:loss = 1.02556e-05, step = 24901 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.321\n",
      "INFO:tensorflow:loss = 1.02119e-05, step = 25001 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 189.743\n",
      "INFO:tensorflow:loss = 1.01602e-05, step = 25101 (0.537 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.667\n",
      "INFO:tensorflow:loss = 1.01006e-05, step = 25201 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.888\n",
      "INFO:tensorflow:loss = 1.00609e-05, step = 25301 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.404\n",
      "INFO:tensorflow:loss = 1.00251e-05, step = 25401 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.601\n",
      "INFO:tensorflow:loss = 9.98539e-06, step = 25501 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.221\n",
      "INFO:tensorflow:loss = 9.92182e-06, step = 25601 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.464\n",
      "INFO:tensorflow:loss = 9.87811e-06, step = 25701 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 282.472\n",
      "INFO:tensorflow:loss = 9.83441e-06, step = 25801 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.21\n",
      "INFO:tensorflow:loss = 9.79864e-06, step = 25901 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.203\n",
      "INFO:tensorflow:loss = 9.75891e-06, step = 26001 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.081\n",
      "INFO:tensorflow:loss = 9.71123e-06, step = 26101 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.087\n",
      "INFO:tensorflow:loss = 9.66752e-06, step = 26201 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.511\n",
      "INFO:tensorflow:loss = 9.63574e-06, step = 26301 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.389\n",
      "INFO:tensorflow:loss = 9.59203e-06, step = 26401 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.888\n",
      "INFO:tensorflow:loss = 9.54832e-06, step = 26501 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.828\n",
      "INFO:tensorflow:loss = 9.50859e-06, step = 26601 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.561\n",
      "INFO:tensorflow:loss = 9.46886e-06, step = 26701 (0.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.207\n",
      "INFO:tensorflow:loss = 9.42515e-06, step = 26801 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.852\n",
      "INFO:tensorflow:loss = 9.38542e-06, step = 26901 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 158.469\n",
      "INFO:tensorflow:loss = 9.34171e-06, step = 27001 (0.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.258\n",
      "INFO:tensorflow:loss = 9.30992e-06, step = 27101 (0.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 166.935\n",
      "INFO:tensorflow:loss = 9.27019e-06, step = 27201 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.794\n",
      "INFO:tensorflow:loss = 9.22648e-06, step = 27301 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.56\n",
      "INFO:tensorflow:loss = 9.18277e-06, step = 27401 (0.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.491\n",
      "INFO:tensorflow:loss = 9.13907e-06, step = 27501 (0.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.928\n",
      "INFO:tensorflow:loss = 9.09536e-06, step = 27601 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.476\n",
      "INFO:tensorflow:loss = 9.06357e-06, step = 27701 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.193\n",
      "INFO:tensorflow:loss = 9.01589e-06, step = 27801 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.301\n",
      "INFO:tensorflow:loss = 8.97616e-06, step = 27901 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.404\n",
      "INFO:tensorflow:loss = 8.94834e-06, step = 28001 (0.472 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.039\n",
      "INFO:tensorflow:loss = 8.91258e-06, step = 28101 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.663\n",
      "INFO:tensorflow:loss = 8.8808e-06, step = 28201 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.504\n",
      "INFO:tensorflow:loss = 8.83709e-06, step = 28301 (0.593 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.6\n",
      "INFO:tensorflow:loss = 8.79338e-06, step = 28401 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.796\n",
      "INFO:tensorflow:loss = 8.75365e-06, step = 28501 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.56\n",
      "INFO:tensorflow:loss = 8.72583e-06, step = 28601 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.313\n",
      "INFO:tensorflow:loss = 8.6861e-06, step = 28701 (0.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.928\n",
      "INFO:tensorflow:loss = 8.64637e-06, step = 28801 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.667\n",
      "INFO:tensorflow:loss = 8.61061e-06, step = 28901 (0.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 184.832\n",
      "INFO:tensorflow:loss = 8.57882e-06, step = 29001 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.592\n",
      "INFO:tensorflow:loss = 8.55101e-06, step = 29101 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.653\n",
      "INFO:tensorflow:loss = 8.5073e-06, step = 29201 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.242\n",
      "INFO:tensorflow:loss = 8.47154e-06, step = 29301 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.986\n",
      "INFO:tensorflow:loss = 8.43975e-06, step = 29401 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.055\n",
      "INFO:tensorflow:loss = 8.40796e-06, step = 29501 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.511\n",
      "INFO:tensorflow:loss = 8.38015e-06, step = 29601 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.881\n",
      "INFO:tensorflow:loss = 8.34439e-06, step = 29701 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.839\n",
      "INFO:tensorflow:loss = 8.32055e-06, step = 29801 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.907\n",
      "INFO:tensorflow:loss = 8.27684e-06, step = 29901 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.193\n",
      "INFO:tensorflow:loss = 8.24903e-06, step = 30001 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.516\n",
      "INFO:tensorflow:loss = 8.21724e-06, step = 30101 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.907\n",
      "INFO:tensorflow:loss = 8.18942e-06, step = 30201 (0.448 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.227\n",
      "INFO:tensorflow:loss = 8.15764e-06, step = 30301 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.302\n",
      "INFO:tensorflow:loss = 8.12982e-06, step = 30401 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.632\n",
      "INFO:tensorflow:loss = 8.10201e-06, step = 30501 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.601\n",
      "INFO:tensorflow:loss = 8.06625e-06, step = 30601 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.756\n",
      "INFO:tensorflow:loss = 8.04638e-06, step = 30701 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.6\n",
      "INFO:tensorflow:loss = 8.01062e-06, step = 30801 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.457\n",
      "INFO:tensorflow:loss = 7.99076e-06, step = 30901 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.15\n",
      "INFO:tensorflow:loss = 7.95499e-06, step = 31001 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.067\n",
      "INFO:tensorflow:loss = 7.93115e-06, step = 31101 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.514\n",
      "INFO:tensorflow:loss = 7.90731e-06, step = 31201 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.24\n",
      "INFO:tensorflow:loss = 7.87155e-06, step = 31301 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.6\n",
      "INFO:tensorflow:loss = 7.83977e-06, step = 31401 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.989\n",
      "INFO:tensorflow:loss = 7.80798e-06, step = 31501 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.686\n",
      "INFO:tensorflow:loss = 7.78811e-06, step = 31601 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.738\n",
      "INFO:tensorflow:loss = 7.76427e-06, step = 31701 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.607\n",
      "INFO:tensorflow:loss = 7.72851e-06, step = 31801 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.242\n",
      "INFO:tensorflow:loss = 7.7007e-06, step = 31901 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.143\n",
      "INFO:tensorflow:loss = 7.65699e-06, step = 32001 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.532\n",
      "INFO:tensorflow:loss = 7.63315e-06, step = 32101 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.464\n",
      "INFO:tensorflow:loss = 7.59739e-06, step = 32201 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.802\n",
      "INFO:tensorflow:loss = 7.57355e-06, step = 32301 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.081\n",
      "INFO:tensorflow:loss = 7.54176e-06, step = 32401 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.526\n",
      "INFO:tensorflow:loss = 7.52189e-06, step = 32501 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.227\n",
      "INFO:tensorflow:loss = 7.49408e-06, step = 32601 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.075\n",
      "INFO:tensorflow:loss = 7.47024e-06, step = 32701 (0.352 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.724\n",
      "INFO:tensorflow:loss = 7.43845e-06, step = 32801 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.698\n",
      "INFO:tensorflow:loss = 7.42256e-06, step = 32901 (0.349 sec)\n",
      "INFO:tensorflow:global_step/sec: 284.884\n",
      "INFO:tensorflow:loss = 7.39077e-06, step = 33001 (0.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.527\n",
      "INFO:tensorflow:loss = 7.35501e-06, step = 33101 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.705\n",
      "INFO:tensorflow:loss = 7.33514e-06, step = 33201 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.192\n",
      "INFO:tensorflow:loss = 7.30733e-06, step = 33301 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.286\n",
      "INFO:tensorflow:loss = 7.29143e-06, step = 33401 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.906\n",
      "INFO:tensorflow:loss = 7.27157e-06, step = 33501 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.041\n",
      "INFO:tensorflow:loss = 7.2358e-06, step = 33601 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.738\n",
      "INFO:tensorflow:loss = 7.20799e-06, step = 33701 (0.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.404\n",
      "INFO:tensorflow:loss = 7.1921e-06, step = 33801 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.667\n",
      "INFO:tensorflow:loss = 7.16826e-06, step = 33901 (0.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.928\n",
      "INFO:tensorflow:loss = 7.13647e-06, step = 34001 (0.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.617\n",
      "INFO:tensorflow:loss = 7.11263e-06, step = 34101 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.438\n",
      "INFO:tensorflow:loss = 7.09276e-06, step = 34201 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.907\n",
      "INFO:tensorflow:loss = 7.06495e-06, step = 34301 (0.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.505\n",
      "INFO:tensorflow:loss = 7.05303e-06, step = 34401 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.328\n",
      "INFO:tensorflow:loss = 7.02521e-06, step = 34501 (0.460 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.192\n",
      "INFO:tensorflow:loss = 6.9974e-06, step = 34601 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.684\n",
      "INFO:tensorflow:loss = 6.97753e-06, step = 34701 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.067\n",
      "INFO:tensorflow:loss = 6.94574e-06, step = 34801 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.668\n",
      "INFO:tensorflow:loss = 6.9219e-06, step = 34901 (0.529 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.389\n",
      "INFO:tensorflow:loss = 6.91396e-06, step = 35001 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.252\n",
      "INFO:tensorflow:loss = 6.89012e-06, step = 35101 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.556\n",
      "INFO:tensorflow:loss = 6.86628e-06, step = 35201 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.721\n",
      "INFO:tensorflow:loss = 6.84641e-06, step = 35301 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.301\n",
      "INFO:tensorflow:loss = 6.82257e-06, step = 35401 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.545\n",
      "INFO:tensorflow:loss = 6.8027e-06, step = 35501 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.208\n",
      "INFO:tensorflow:loss = 6.76694e-06, step = 35601 (0.366 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.208\n",
      "INFO:tensorflow:loss = 6.74707e-06, step = 35701 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.096\n",
      "INFO:tensorflow:loss = 6.73515e-06, step = 35801 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.993\n",
      "INFO:tensorflow:loss = 6.71131e-06, step = 35901 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.466\n",
      "INFO:tensorflow:loss = 6.69939e-06, step = 36001 (0.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.992\n",
      "INFO:tensorflow:loss = 6.67555e-06, step = 36101 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 288.168\n",
      "INFO:tensorflow:loss = 6.65171e-06, step = 36201 (0.347 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.883\n",
      "INFO:tensorflow:loss = 6.62787e-06, step = 36301 (0.356 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.71\n",
      "INFO:tensorflow:loss = 6.608e-06, step = 36401 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 278.536\n",
      "INFO:tensorflow:loss = 6.59211e-06, step = 36501 (0.359 sec)\n",
      "INFO:tensorflow:global_step/sec: 280.096\n",
      "INFO:tensorflow:loss = 6.57224e-06, step = 36601 (0.358 sec)\n",
      "INFO:tensorflow:global_step/sec: 285.698\n",
      "INFO:tensorflow:loss = 6.55237e-06, step = 36701 (0.353 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.802\n",
      "INFO:tensorflow:loss = 6.52853e-06, step = 36801 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.389\n",
      "INFO:tensorflow:loss = 6.50867e-06, step = 36901 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.321\n",
      "INFO:tensorflow:loss = 6.4888e-06, step = 37001 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.684\n",
      "INFO:tensorflow:loss = 6.45701e-06, step = 37101 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.457\n",
      "INFO:tensorflow:loss = 6.44509e-06, step = 37201 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.754\n",
      "INFO:tensorflow:loss = 6.42125e-06, step = 37301 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.828\n",
      "INFO:tensorflow:loss = 6.39344e-06, step = 37401 (0.525 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.808\n",
      "INFO:tensorflow:loss = 6.37754e-06, step = 37501 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.457\n",
      "INFO:tensorflow:loss = 6.3537e-06, step = 37601 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.252\n",
      "INFO:tensorflow:loss = 6.33383e-06, step = 37701 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.009\n",
      "INFO:tensorflow:loss = 6.31397e-06, step = 37801 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.663\n",
      "INFO:tensorflow:loss = 6.29013e-06, step = 37901 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.26\n",
      "INFO:tensorflow:loss = 6.26628e-06, step = 38001 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.327\n",
      "INFO:tensorflow:loss = 6.25436e-06, step = 38101 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.58\n",
      "INFO:tensorflow:loss = 6.23847e-06, step = 38201 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.888\n",
      "INFO:tensorflow:loss = 6.2186e-06, step = 38301 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.6\n",
      "INFO:tensorflow:loss = 6.19476e-06, step = 38401 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.121\n",
      "INFO:tensorflow:loss = 6.17887e-06, step = 38501 (0.467 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.684\n",
      "INFO:tensorflow:loss = 6.14708e-06, step = 38601 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.194\n",
      "INFO:tensorflow:loss = 6.13913e-06, step = 38701 (0.524 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.389\n",
      "INFO:tensorflow:loss = 6.11927e-06, step = 38801 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.959\n",
      "INFO:tensorflow:loss = 6.11132e-06, step = 38901 (0.531 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.202\n",
      "INFO:tensorflow:loss = 6.09145e-06, step = 39001 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.777\n",
      "INFO:tensorflow:loss = 6.07556e-06, step = 39101 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.053\n",
      "INFO:tensorflow:loss = 6.05569e-06, step = 39201 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.072\n",
      "INFO:tensorflow:loss = 6.04377e-06, step = 39301 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.24\n",
      "INFO:tensorflow:loss = 6.01596e-06, step = 39401 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.58\n",
      "INFO:tensorflow:loss = 6.00404e-06, step = 39501 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.921\n",
      "INFO:tensorflow:loss = 5.98417e-06, step = 39601 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.654\n",
      "INFO:tensorflow:loss = 5.96827e-06, step = 39701 (0.458 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.464\n",
      "INFO:tensorflow:loss = 5.95238e-06, step = 39801 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 283.27\n",
      "INFO:tensorflow:loss = 5.93649e-06, step = 39901 (0.353 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into C:\\Users\\ACER\\AppData\\Local\\Temp\\tmpc03kpxuk\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.90867e-06.\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\ACER\\AppData\\Local\\Temp\\tmpc03kpxuk\\model.ckpt-40000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35833333333333334"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test,y_train, y_test = train_test_split(x,y, train_size = 0.2, random_state = 42)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scale = MinMaxScaler()\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(scale.fit_transform(x_train))\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units = [300,100], n_classes = 10,\n",
    "                                        feature_columns = feature_cols)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf) # if Tensorflow <= 1.1\n",
    "dnn_clf.fit(x_train, y_train, batch_size = 50, steps = 40000)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = dnn_clf.predict(scale.fit_transform(x_test))\n",
    "accuracy_score(y_test, y_pred['classes'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a DNN using plain TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construction phase\n",
    "# in this section we will build the same model as before using this\n",
    "# API, and we will implement the gradient Descent to train it on the\n",
    "# MNIST dataset.\n",
    "# the first step is the construction phase, building the tensorflow graph.\n",
    "# The second step is the execution phase, where you actually run the graph\n",
    "# mto train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable hidden1/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d982526bd296>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dnn\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[0mhidden1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_hidden1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"hidden1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m     \u001b[0mhidden2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_hidden2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"hidden2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"outputs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\u001b[0m in \u001b[0;36mdense\u001b[1;34m(inputs, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[0;32m    248\u001b[0m                 \u001b[0m_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m                 _reuse=reuse)\n\u001b[1;32m--> 250\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    669\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m     \"\"\"\n\u001b[1;32m--> 671\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m   def _add_inbound_node(self,\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m           \u001b[0minput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minput_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    135\u001b[0m                                     \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                                     trainable=True)\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m       self.bias = self.add_variable('bias',\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36madd_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint)\u001b[0m\n\u001b[0;32m    456\u001b[0m                                    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m                                    \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m                                    trainable=trainable and self.trainable)\n\u001b[0m\u001b[0;32m    459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvariable\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexisting_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1201\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m       constraint=constraint)\n\u001b[0m\u001b[0;32m   1204\u001b[0m get_variable_or_local_docstring = (\n\u001b[0;32m   1205\u001b[0m     \"\"\"%s\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1090\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1092\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m   1093\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1094\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m    423\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m           \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    392\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    740\u001b[0m                          \u001b[1;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 742\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    743\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable hidden1/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# construction phase\n",
    "# starting by specifying the number of inputs and outputs, and set the number\n",
    "# of hidden neurons in each layer:\n",
    "\n",
    "import tensorflow as tf\n",
    "n_inputs = 28*28 # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2= 100\n",
    "n_outputs = 10\n",
    "\n",
    "# we can use placeholder nodes to represent the training data and \n",
    "# target data. The shape of x is only partially defined.\n",
    "# since we do not know the number of training batch for x and y\n",
    "# we set the shape for x to be (none, inputs) and y as (none).\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape = (None, n_inputs), name = \"x\")\n",
    "y = tf.placeholder(tf.int64, shape = (None), name = \"y\")\n",
    "\n",
    "# the placeholder X will act as the input layer; during the execution phase\n",
    "# it will be replaced with one training batch at a time.\n",
    "# we need to create the two hidden layers and the output layers.\n",
    "# The two hidden layers are almost identical: they differ only by the inputs\n",
    "# they are connected to and by the number of neurons they contain.\n",
    "\n",
    "# the output layer is also very similar, but it uses a softmax activation function\n",
    "# instead of a ReLU activiation function.\n",
    "\n",
    "#The function neuron_layer() is used to create one layer at a time.\n",
    "\n",
    "def neuron_layer(x, n_neurons, name, activation = None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(x.get_shape()[1])\n",
    "        stddev = 2/np.sqrt(n_inputs + n_neurons)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev = stddev)\n",
    "        W = tf.Variable(init, name = \"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons]), name = \"bias\")\n",
    "        z = tf.matmul(x,W) + b\n",
    "        if activation is not None:\n",
    "            return activation(z)\n",
    "        \n",
    "        else:\n",
    "            return z\n",
    "# if activation parameter is provided, such as tf.nn.relu(i.e.max(0,Z)),\n",
    "# then the code returns activation(Z), or else it just returns Z.\n",
    "\n",
    "# since we have crated the neuron layer. we can now create the deep\n",
    "# neural network.\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(x, n_hidden1, name = \"hidden1\", \n",
    "                          activation = tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name = \"hidden2\", \n",
    "                          activation = tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name = \"outputs\")\n",
    "    \n",
    "    \n",
    "# as you might expect tensorflow comes with many handy function\n",
    "# TensorFlow's tf.layers.dense() function (previously called tf.contrib.layers.fully_connected())\n",
    "#creates a fully connected layer, where all the inputs are connected to all\n",
    "# neurons in the layer.\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(x, n_hidden1, name = \"hidden1\", activation = tf.nn.relu)\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name = \"hidden2\", activation = tf.nn.relu)\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name = \"outputs\")\n",
    "    \n",
    "# we need to define the cost function that we will use to train the neural network model.\n",
    "# we will use cross entropy. It penalizes models that estimate a low probability for the \n",
    "# target class.\n",
    "\n",
    "# using the sparse_soft_max_cross_entropy_with_logits(), it computes\n",
    "# the cross entropy based on the logits.\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels = y, logits = logits)\n",
    "    loss = tf.reduce_mean(xentropy, name = 'loss')\n",
    "    \n",
    "# this computes the cross entropy based on the \"logit\".\n",
    "\n",
    "# now we have the neural network model, we have the cost function and\n",
    "# now we need to define a GradientDescentOptimizer that will tweak the \n",
    "# model parameters to minimize the cost function.\n",
    "\n",
    "learing_rate = 0.01\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "# evaluation and performance measure of the neural network model.\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y,1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    #  create node to initialize all variables and also create a saver\n",
    "    # to save our trained model parameters to disk.\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    # this concludes the construction phase.\n",
    "    \n",
    "# we created a function to build a neuron layer, we used it to create the\n",
    "# DNN, we defined the cost function, we created an optimizer, and finally we\n",
    "# defined the performance measure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution phase\n",
    "\n",
    "# first let's load the MNIST\n",
    "# Tensorflow offers its own helper that fetches the data, scales it \n",
    "# (between 0 and 1), shuffle it, and provides a simple function to load one\n",
    "# mini-batch a time. moreover the data has been split into training, validation\n",
    "# and test set.\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(r\"C:\\Users\\ACER\\Desktop\\pyreach\\Life Data\\Tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now defining the number of epochs that we want to run as well as the\n",
    "# size of the mini-batches:\n",
    "n_epochs = 40\n",
    "batch_size = 50\n",
    "\n",
    "# train the model\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            x_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict = {x: x_batch, y: y_batch})\n",
    "        acc_train = accuracy.eval(feed_dict = {x: x_batch, y: y_batch})\n",
    "        acc_val = accuracy.eval(feed_dict = {x: mnist.validation.images, \n",
    "                                            y: mnist.validation.labels})\n",
    "        print (epoch, \"train accuracy: \", acc_train, \"val_accuracy: \", acc_val)\n",
    "    save_path = saver.save(sess, \"C:\\Users\\ACER\\Desktop\\pyreach\\Life Data\\Tensorflow\\neural_model.ckpt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the Neural Network\n",
    "# now that the neural network is trained, we can now use it to make\n",
    "# predictions.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"rC:\\Users\\ACER\\Desktop\\pyreach\\Life Data\\Tensorflow\\neural_model.ckpt\")\n",
    "    x_new_scaled = [....] # some new images to be predicted\n",
    "    z = logits.eval(feed_dict = {x: x_new_scaled})\n",
    "    y_pred = np.argmax(z, axis = 1)\n",
    "    \n",
    "# parameter hypertuning, through the use of oscar or randomized search instead of gridsearch\n",
    "# and cross_validation.\n",
    "\n",
    "# Number of hidden layers.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "x, y = iris.data, iris.target\n",
    "\n",
    "import tensorflow as tf\n",
    "n_hidden1 = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.dtype' object has no attribute 'base_dtype'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-75ffe8470a7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mhe_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariance_scaling_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mhidden1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_hidden1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhe_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\ACER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\core.py\u001b[0m in \u001b[0;36mdense\u001b[1;34m(inputs, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m                 \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m                 \u001b[0m_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m                 _reuse=reuse)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.dtype' object has no attribute 'base_dtype'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# using the Xavier initialization strategy we can speed p training\n",
    "# considerably, and it is one of the tricks that led to the current success\n",
    "# of deep learning.\n",
    "\n",
    "# by default, the tf.layers.dense() function uses Xavier intialization (with a uniform)\n",
    "# distribution). You can change this to He intialization by using the variance_scaling_initializer()\n",
    "# function like this\n",
    "\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "hidden1 = tf.layers.dense(x, n_hidden1, activation = tf.nn.relu, kernel_initializer = he_init,\n",
    "                         name = 'hidden1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nonsaturating activation functions \n",
    "# the use of leakyRelu function out perfroms the normal ReLU function.\n",
    "# leakyRelu function out perfroms the relu on large image datasets but on smaller datasets\n",
    "# it runs the risk of overfitting the training set.\n",
    "\n",
    "# a 2015 paper by Djork-Arne Clevert et al proposed a new activiation function\n",
    "# called the exponential linear unit (ELU) that outperformed all the RELU\n",
    "# variants in their experiments.\n",
    "\n",
    "# the major drawback of ELU activation function is that it is slower to compute\n",
    "# than the ReLu and its variants (due to the use of exponential function), but \n",
    "# during training this is compensated by the faster convergence rate.\n",
    "\n",
    "# Tensorflow offers an elu() function that you can use to build your neural network.\n",
    "\n",
    "hidden1 = tf.layers.dense(x, n_hidden1, activation = tf.nn.elu, name = 'hidden1')\n",
    "\n",
    "def leaky_relu(z, name = None):\n",
    "    return tf.maximum(0.01 * z,z, name = name)\n",
    "\n",
    "\n",
    "hidden1 = tf.layers.dense(x, n_hidden1, activation = leaky_relu, name = \"hidden1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Normalization\n",
    "\n",
    "# although using He initialization along with ELU (or any variant of Relu) \n",
    "# can significantly reduce the vanishing/exploding gradients problems at the\n",
    "# beginning of training, it doesn't gurantee that they won't come back during\n",
    "# training.\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape = (None, n_inputs), name = 'x')\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape = (), name = 'training')\n",
    "\n",
    "hidden1 = tf.layers.dense(x, n_hidden1, name = \"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training = training, momentum = 0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name = \"hidden2\")\n",
    "bn2 = tf.layers.batch_normalization(hidden2, training= training, momentum = 0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name = 'outputs')\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training = training, \n",
    "                                      momentum = 0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
